# AI2Text - Vietnamese Speech-to-Text System

## ğŸ‰ **NOW PRODUCTION-READY!** Enterprise Microservices Platform

A comprehensive, production-ready Automatic Speech Recognition (ASR) system designed for Vietnamese language with complete microservices architecture. Built for both training and deployment at scale.

### âš¡ **NEW: Production-Grade Multi-Project Architecture**

Your project now includes a **complete production implementation** in the `projects/` directory:
- âœ… **8 Microservices** (Gateway, Ingestion, ASR, NLP-Post, Embeddings, Search, Metadata, Training)
- âœ… **Contract-First Development** (OpenAPI/AsyncAPI v1.1.0 with versioning)
- âœ… **SLO Tracking** (Grafana dashboards + Prometheus alerts)
- âœ… **Performance Testing** (k6 load tests for all services)
- âœ… **Production Roadmap** (Nov-Dec 2025 sprint plan to GA)

**ğŸš€ START HERE**: **[README_PRODUCTION_READY.md](README_PRODUCTION_READY.md)** | **[projects/README.md](projects/README.md)**

---

## ğŸš€ Quick Start - Microservices (NEW!)

Get the complete ASR stack running in 5 minutes:

```bash
# 1. Bootstrap infrastructure
bash scripts/bootstrap.sh

# 2. Start all services
docker compose -f infra/docker-compose.yml up -d

# 3. Verify setup
python3 scripts/verify_setup.py

# 4. Test the API
python3 scripts/jwt_dev_token.py  # Get auth token
# Then upload audio via http://localhost:8080/v1/ingest
```

**ğŸ“š For detailed setup:** See [`RUN_GUIDE.md`](RUN_GUIDE.md)  
**ğŸ¯ Quick commands:** See [`QUICK_REFERENCE.md`](QUICK_REFERENCE.md)  
**ğŸ—ï¸ Architecture:** See [`MICROSERVICES_SETUP_GUIDE.md`](MICROSERVICES_SETUP_GUIDE.md)

---

## ğŸŒŸ Features

### Microservices Architecture (Production-Ready)
- **API Gateway**: JWT authentication, rate limiting (60/min), CORS support
- **Real-time Streaming**: WebSocket-based ASR with sub-100ms latency
- **Batch Processing**: Async pipeline with event-driven processing (NATS)
- **Vietnamese NLP**: Automatic diacritics restoration & typo correction
- **Semantic Search**: Vector-based search over transcripts (Qdrant)
- **Three-Tier Storage**: S3 (audio) + PostgreSQL (metadata) + Vector DB (embeddings)
- **Speaker-Level Split**: Database-enforced data split to prevent leakage
- **One-Command Setup**: Complete stack running in 5 minutes

### Model Training
- **Transformer-based Architecture**: Modern encoder with CTC loss
- **Vietnamese Language Support**: Specialized text normalization & tokenization
- **Resource-Efficient**: Mixed precision, gradient accumulation, efficient data loading
- **Complete Pipeline**: End-to-end from preprocessing to deployment
- **Database Integration**: Experiment tracking with SQLite/PostgreSQL
- **Modular Design**: Easy to extend individual components
- **Audio Augmentation**: Built-in augmentation for robust training

## ğŸ“ Project Structure

> **Note**: Documentation has been reorganized. See `docs/PROJECT_ORGANIZATION.md` for details.
> - Architecture docs: `docs/architecture/`
> - User guides: `docs/guides/`
> - Requirements: `requirements/`

```
AI2text/
â”œâ”€â”€ data/                      # Data storage
â”‚   â”œâ”€â”€ raw/                   # Raw audio files
â”‚   â”œâ”€â”€ processed/             # Preprocessed data
â”‚   â””â”€â”€ external/              # External datasets
â”‚
â”œâ”€â”€ database/                  # Database management
â”‚   â”œâ”€â”€ init_db.sql           # Database schema
â”‚   â”œâ”€â”€ db_utils.py           # Database utilities
â”‚   â””â”€â”€ asr_training.db       # SQLite database (created on first run)
â”‚
â”œâ”€â”€ models/                    # Model architectures
â”‚   â”œâ”€â”€ asr_base.py           # Base transformer ASR model
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ training/                  # Training pipeline
â”‚   â”œâ”€â”€ dataset.py            # Dataset and data loaders
â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â”œâ”€â”€ evaluate.py           # Evaluation and inference
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ preprocessing/             # Audio and text preprocessing
â”‚   â”œâ”€â”€ audio_processing.py   # Audio feature extraction and augmentation
â”‚   â”œâ”€â”€ text_cleaning.py      # Vietnamese text normalization and tokenization
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â”œâ”€â”€ default.yaml          # Default training config
â”‚   â””â”€â”€ db.yaml               # Database config
â”‚
â”œâ”€â”€ utils/                     # Utilities
â”‚   â”œâ”€â”€ metrics.py            # WER, CER calculation
â”‚   â”œâ”€â”€ logger.py             # Logging setup
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/                   # Helper scripts
â”‚   â”œâ”€â”€ prepare_data.py       # Data preparation and import
â”‚   â””â”€â”€ download_sample_data.py
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for experimentation
â”œâ”€â”€ File kiáº¿n thá»©c/           # Knowledge base documents
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements/base.txt
```

### 2. Prepare Your Data

Your data should be organized in a CSV file with the following columns:

- `file_path`: Path to audio file (WAV, MP3, FLAC, OGG)
- `transcript`: Vietnamese transcription text
- `split` (optional): 'train', 'val', or 'test'
- `speaker_id` (optional): Speaker identifier

Example CSV:
```csv
file_path,transcript,split,speaker_id
data/raw/audio1.wav,xin chÃ o viá»‡t nam,train,speaker_01
data/raw/audio2.wav,tÃ´i lÃ  sinh viÃªn,train,speaker_02
data/raw/audio3.wav,hÃ´m nay trá»i Ä‘áº¹p,val,speaker_01
```

### 3. Import Data into Database

```bash
# Import data from CSV
python scripts/prepare_data.py --csv your_data.csv --audio_base data/raw --auto_split

# The --auto_split flag automatically creates train/val/test splits if not specified in CSV
```

### 4. Train the Model

```bash
# Train with default configuration
python training/train.py --config configs/default.yaml

# Resume from checkpoint
python training/train.py --config configs/default.yaml --resume checkpoints/checkpoint_epoch_10.pt
```

### 5. Evaluate the Model

```bash
# Evaluate on test set
python training/evaluate.py --config configs/default.yaml --checkpoint checkpoints/best_model.pt --split test --output results/evaluation.csv

# Transcribe a single audio file
python training/evaluate.py --config configs/default.yaml --checkpoint checkpoints/best_model.pt --audio path/to/audio.wav
```

## ğŸ“Š Database Schema

The system uses SQLite to track:

- **AudioFiles**: Audio file metadata (duration, sample rate, quality)
- **Transcripts**: Ground truth transcriptions
- **DataSplits**: Train/validation/test split assignments
- **Models**: Model architectures and configurations
- **TrainingRuns**: Training experiments with hyperparameters
- **EpochMetrics**: Per-epoch training metrics
- **Predictions**: Model predictions for analysis

View training history:
```python
from database.db_utils import ASRDatabase

db = ASRDatabase()
history = db.get_training_history(training_run_id=1)
summary = db.get_training_runs_summary(limit=10)
best_model = db.get_best_model(metric='word_error_rate')
```

## âš™ï¸ Configuration

Edit `configs/default.yaml` to customize training:

```yaml
# Model architecture
d_model: 256                # Model dimension
num_encoder_layers: 6       # Number of transformer layers
num_heads: 4                # Attention heads
d_ff: 1024                  # Feed-forward dimension

# Training
batch_size: 16              # Batch size (reduce for weak GPU)
num_epochs: 50              # Training epochs
learning_rate: 0.0001       # Learning rate
use_amp: true               # Mixed precision training

# Audio processing
sample_rate: 16000          # Target sample rate
n_mels: 80                  # Mel spectrogram bands
```

### Optimization for Weak Hardware

For computers with limited resources:

1. **Reduce batch size**: Set `batch_size: 4` or `8`
2. **Reduce model size**: 
   - `d_model: 128`
   - `num_encoder_layers: 4`
   - `d_ff: 512`
3. **Enable mixed precision**: `use_amp: true` (requires CUDA)
4. **Reduce workers**: `num_workers: 2`

## ğŸ“ˆ Model Architecture

The system uses a transformer-based encoder architecture with:

- **Convolutional Subsampling**: Reduces sequence length for efficiency
- **Multi-head Self-Attention**: Captures long-range dependencies
- **Position-wise Feed-Forward**: Non-linear transformations
- **CTC Loss**: Connectionist Temporal Classification for alignment-free training

Total parameters with default config: ~15M (highly efficient!)

## ğŸ¯ Performance Metrics

The system tracks:

- **WER (Word Error Rate)**: Primary metric for ASR evaluation
- **CER (Character Error Rate)**: Character-level accuracy
- **Training Loss**: Cross-entropy loss during training
- **Validation Loss**: Generalization performance

## ğŸ“ Text Normalization

Vietnamese-specific preprocessing:

- Unicode normalization (NFC)
- Number-to-word conversion (0 â†’ khÃ´ng, 1 â†’ má»™t)
- Abbreviation expansion (tp. â†’ thÃ nh phá»‘)
- Filler word removal (á»«m, Ã , á»)
- Tone mark preservation
- Lowercase conversion

## ğŸ”Š Audio Preprocessing

Audio augmentation techniques:

- **Noise addition**: Gaussian noise for robustness
- **Time stretching**: 0.8x - 1.2x speed variations
- **Pitch shifting**: Â±2 semitones
- **Volume changes**: 0.5x - 1.5x gain
- **SpecAugment**: Frequency and time masking
- **Background noise mixing**: SNR-based noise addition

## ğŸ“š Knowledge Base

The `File kiáº¿n thá»©c/` folder contains reference materials on:

- Deep learning architectures for fast convergence
- Modern Sound-to-Text technologies
- Contextual word embeddings
- Advanced ASR data management
- Training optimization for weak hardware
- Audio processing, NLP, and Vietnamese language handling

These documents inform the design decisions in this system.

## ğŸ› ï¸ Development

### Adding New Features

1. **New Model Architecture**: Add to `models/` directory
2. **Custom Augmentation**: Extend `AudioAugmenter` class
3. **Different Loss Function**: Modify training script
4. **New Metrics**: Add to `utils/metrics.py`

### Code Style

- Follow PEP 8 guidelines
- Use type hints
- Add docstrings to functions and classes
- Keep functions focused and modular

## ğŸ› Troubleshooting

### Common Issues

**Out of Memory (OOM)**:
- Reduce `batch_size` in config
- Enable `use_amp: true`
- Reduce model size parameters

**Slow Training**:
- Increase `num_workers` for data loading
- Enable mixed precision training
- Use GPU if available

**Database Locked**:
- Close other connections to database
- Check file permissions

**Audio Loading Errors**:
- Verify audio file formats (WAV recommended)
- Check file paths in CSV
- Ensure sample rates are supported

## ğŸ“„ License

[Specify your license here]

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“§ Contact

[Your contact information]

## ğŸ™ Acknowledgments

This system is built using modern ASR techniques and optimized for Vietnamese language processing. Special thanks to the research community for advances in transformer architectures and speech recognition.

---

**Note**: This is a research/educational implementation. For production use, consider additional optimizations, error handling, and security measures.
